---
title: "Loading Data"
---

## Getting started with pandas

Pandas is a powerful and widely used library in Python for data manipulation and analysis. It provides versatile data structures, such as DataFrames and Series, along with a variety of functions and methods for efficiently handling and processing structured data. In this session, we explore some functionalities of Pandas library that is useful for biological data analysis.

Customarily, we import the library as follows:

```{python}
import pandas as pd
```

To open the help documentation for the `pandas` package, you can use the following code:

::: scrolling
```{python}
import pandas as pd
help(pd)
```
:::

This will display the help documentation for the Pandas library, providing an overview of its functions, modules, and usage.

### Basic data structures in pandas

Pandas provides two types of classes for handling data: **`Series`** and **`DataFrame`**.

### Series

`Series` is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. The basic method to create a `Series` is to call:

``` python
s = pd.Series(data, index=index)
```

Here, **data** can be a Python dict, an ndarray (a multidimensional container of items of the same type and size) or a scalar value. The passed **index** is a list of axis labels.

To open the help page for Series, you can use the following code:

```{python}
#| eval: false
import pandas as pd
help(pd.Series)  
# or help(pandas.Series)
```

::: scrolling
```{python}
#| echo: false
import pandas as pd
help(pd.Series)  
# or help(pandas.Series)
```
:::

#### Using a list:

```{python}
s1 = pd.Series([1, 3, 5, 6, 8])
s1
```

#### Using a scalar (single value):

```{python}
s2 = pd.Series(5.0, index=["a", "b", "c", "d", "e"])
s2
```

#### Using a numpy array:

To create a `Series` using ndarray first import numpy library.

```{python}
import numpy as np
```

NumPy, short for Numerical Python, is a fundamental Python library for scientific computing. It provides support for working with large, multi-dimensional arrays and matrices, as well as a collection of high-level mathematical functions to operate on these arrays.

```{python}
s3 = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])
s3
```

The np.random module in NumPy is designed for generating pseudo-random numbers, enabling you to extract samples from a wide range of probability distributions. Specifically, the np.random.randn function is used to obtain one or more samples from the "standard normal" distribution, characterized by a mean of 0 and a variance of 1.

If data is an ndarray, index must be the same length as data. If no index is passed, one will be created having values \[0, ..., len(data) - 1\].

```{python}
s3 = pd.Series(np.random.randn(5))
s3
```

#### Using a dictionary:

`Series` can be instantiated from dicts (recall dictionary from last week) as follows:

```{python}
d = {"A": 248, "C": 243, "G": 266, "T": 243}
s4 = pd.Series(d)
s4
```

```{python}
s4 = pd.Series(dict, index=["A", "B", "C"])
s4
```

## DataFrame

`DataFrame` is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. The `DataFrame` is generally the most commonly used pandas object. It accepts many different types of input including dictionary of 1-D ndarrays, lists, dictionaries or Series, 2-D ndarray, a Series or even another DataFrame.

Along with the data, you can optionally pass index (row labels) and columns (column labels) arguments. If you pass an index and/or columns, you are guaranteeing the index and/or columns of the resulting DataFrame.

The basic method to create a `DataFrame` is to call:

``` python
df = pd.DataFrame(data, index=index, columns=columns)
```

To open the help page for DataFrame, you can use the following code:

```{python}
#| eval: false
import pandas as pd
help(pd.DataFrame)  
# or help(pandas.DataFrame)
```

::: scrolling
```{python}
#| echo: false
import pandas as pd
help(pd.DataFrame)  
# or help(pandas.DataFrame)
```
:::

This will display the help documentation for the `DataFrame` class in Pandas, including information on its methods, attributes, and usage examples.

### Creating a `DataFrame` by using a dictionary of `Series`:

```{python}
# a dictionary of series
d = {
    "Col 1": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "c"]),
    "Col 2": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
}
df1 = pd.DataFrame(d)
df1
```

```{python}
# table with rows: d, b  and a of the above dictionary
df2 = pd.DataFrame(d, index=["d", "b", "a"])
df2
```

Note: **NaN**, standing for **not a number**, is a numeric data type used to represent any value that is undefined. It is by default not included in computations.

### Creating a `DataFrame` by using a dictionary of `Series`, lists, ndarrays:

```{python}
# a dictionary 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': pd.Series([25, 30, 35, 40]),
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston'],
    'Salary': np.array([50000, 60000, 75000, 90000])
}

df3 = pd.DataFrame(data)
df3
```

### Indexes and Columns of `DataFrames`

Consider the following DataFrame,

```{python}
d = {"one": [1.0, 2.0, 3.0, 4.0], "two": [4.0, 3.0, 2.0, 1.0]}
df3 = pd.DataFrame(d, index=["a", "b", "c", "d"])
df3
```

To print and update row names:

```{python}
df3.index = ["row 1", "row 2", "row 3", "row 4"]
df3
```

To print and update column names:

```{python}
df3.columns = ["Column_1", "Column_2"]
df3
```

This method is straightforward if you want to rename all columns at once, but make sure the list you provide matches the number of columns in the DataFrame.

To rename columns in a DataFrame, you can use the `rename()` method:

```{python}
# Rename columns using a dictionary
df3_renamed = df3.rename(columns={'Column_1': 'new_name1', 'Column_2': 'new_name2'})

# Display the updated DataFrame
df3_renamed
```

Here the `columns` parameter takes a dictionary where the keys are the old column names and the values are the new column names. This method does **not** modify the original DataFrame unless you specify `inplace=True`.

To print the data type of each column:

```{python}
df = pd.DataFrame(
    {
        "A": np.random.uniform(low=0, high=1, size=12),
        "B": pd.date_range(start="20230102", periods=12),
        "C": pd.Series(range(1, 13), index=["R1", "R2", "R3", "R4", "R5", "R6", "R7", "R8" ,"R9", "R10", "R11", "R12"]),
        "D": np.random.randint(1, high=100, size=12),
        "E": pd.Categorical(["red", "green", "blue", "white", "pink", "brown", "black", "purple", "orange", "grey", "violet", "yellow"]),
        "F": "foo",
    }, index = ["R1", "R2", "R3", "R4", "R5", "R6", "R7", "R8" ,"R9", "R10", "R11", "R12"]
)
print(df.dtypes)
```

## Reading and Writing to a file

Up to this point, all the data we've been dealing with has been manually entered into our scripts, and the outcomes of our computations have simply been displayed in the terminal. However, in the real world, data will typically be provided by the users of our programs (which could include you!), and we often need to store the results of our analyses in a more permanent location than just printing them to the screen. During this session, we'll explore a few commonly used methods for importing data into our programs by reading/writing files from disk using the pandas library.

It's worth noting that there are numerous other ways to access data, such as querying a database or retrieving data from a network, such as the internet. While we won't cover these methods in this session, Python offers excellent support for interacting with databases and networks, either through its standard library or via external modules.

### Comma-Seperated Values (CSV) file or Text file

Read a CSV or text file:

``` python
pd.read_csv("path_to_file.csv")

# read a text file with values separated by spaces
pd.read_csv("path_to_file.txt", sep=' ')
```

Write a DataFrame `df` to a CSV or text file:

``` python
df.to_csv("path_to_file.csv")
df.to_csv("path_to_file.txt")
```

### Excel file

Read an excel file:

``` python
pd.read_excel("path_to_file.xls", sheet_name="Sheet1")
pd.read_excel("path/to/file/name/file_name.csv")
```

Write a DataFrame `df` to an excel file:

``` python
df.to_excel("path_to_file.xlsx", sheet_name="Sheet1")
```

::: {.callout-tip}
### Challenge {.unlisted}

**Read the CSV file associated with the Metabric dataset from this link into a Pandas DataFrame named `metabric`: ["https://zenodo.org/record/6450144/files/metabric_clinical_and_expression_data.csv"](%22https://zenodo.org/record/6450144/files/metabric_clinical_and_expression_data.csv%22).**

::: {.callout-note collapse="true"}
### Solution

```{python}
import pandas as pd

# Load the Metabric dataset from the URL into a DataFrame
metabric = pd.read_csv("https://zenodo.org/record/6450144/files/metabric_clinical_and_expression_data.csv")
```
:::

:::

## Viewing data

The `DataFrame` class offers multiple methods to view and interact with data. Below are some useful methods and how to access their help documentation.

To open the help page for any method in the `DataFrame` class, use the following code.

```{python}
#| eval: false
import pandas as pd
help(pd.DataFrame.method_name)
# or help(pandas.DataFrame.method_name)
```


For example, to open the help page for `DataFrame.head()`:

```{python}
#| eval: false
import pandas as pd
help(pd.DataFrame.head)  
# or help(pandas.DataFrame.head)
```

::: scrolling
```{python}
#| echo: false
import pandas as pd
help(pd.DataFrame.head)  
# or help(pandas.DataFrame.head)
```
:::

Similarly, to open the help page for `DataFrame.columns`:

```{python}
#| eval: false
import pandas as pd
help(pd.DataFrame.columns)  
# or help(pandas.DataFrame.columns)
```

::: scrolling
```{python}
#| echo: false
import pandas as pd
help(pd.DataFrame.columns)  
# or help(pandas.DataFrame.columns)
```
:::

This approach works for any other method or attribute of the `DataFrame` class.

-   Use `DataFrame.head()` to view the top rows of the DataFrame. It returns the top 5 rows of the DataFrame.
    ```{python}
    df.head()
    ```

-   `DataFrame.tail()` shows the last 5 rows of the DataFrame.

    ```{python}
    df.tail()
    ```

-   `DataFrame.index` returns the index (row labels) of the DataFrame.

    ```{python}
    df.index
    ```

-   `DataFrame.columns` returns the column names of the DataFrame.

    ```{python}
    df.columns
    ```

-   `DataFrame.dtypes` shows the data type of each column in the DataFrame, allowing you to understand what kind of data each column holds (e.g., integers, floats, or strings).

    ```{python}
    df.dtypes
    ```

-   To get the **shape** of the DataFrame (i.e., the number of rows and columns), use:

    ```{python}
    df.shape
    ```

-   To get the **dimensions** of the DataFrame (i.e., the number of axes: rows and columns), use:

    ```{python}
    df.ndim
    ```

-   To get the number of **rows** in the DataFrame, use:

    ```{python}
    df.shape[0]
    ```

-   To get the number of **columns** in the DataFrame, use:

    ```{python}
    df.shape[1]
    ```

-   To get a NumPy representation of the underlying data without the index or column labels, use:

    ```{python}
    df.to_numpy()
    ```

-   `DataFrame.describe()` provides a quick statistical summary of the data. This summary includes:

    -   **count**: The number of rows for each column.
    -   **mean**: The average value for each numerical column.
    -   **std**: The standard deviation, which measures how spread out the values are.
    -   **min**: The minimum value for each column.
    -   **percentiles**: Includes the 25th, 50th (median), and 75th percentiles, also known as the 1st, 2nd, and 3rd quartiles.
    -   **max**: The maximum value in each column.

    ```{python}
    df.describe()
    ```

-   The `DataFrame.info()` method provides a concise summary of the DataFrame's structure. It is particularly useful for quickly inspecting the basic details of a DataFrame, such as its index, column names, data types, and memory usage.

    ```{python}
    df.info()
    ```

-   `DataFrame.t` transpose your data. This results in a DataFrame where the columns of the DataFrame are now rows and the rows are now columns.

    ```{python}
    df.T
    ```

-   `DataFrame.sort_index()` sorts by an axis. If no arguments are provided to this function, it restore to default value where `axis = 0` (same as `axis = 'index'`) (rows).`axis = 1` (same as `axis = 'columns'`) argument sort based on columns. This sorts the column labels rather than values in the table. This function accepts another argument called `ascending` which takes a boolean value (True or False).

    ```{python}
    df.sort_index(axis=1, ascending=False)
    ```

-   `DataFrame.sort_values()` sorts based on columns. The by argument takes a name or list of column names to sort the DataFrame.

    ```{python}
    df.sort_values(by="E")
    ```

::: {.callout-tip}
### Challenge {.unlisted}

1.  Print the top 5 and the bottom 5 rows of the `metabric` dataset.
2.  Provide a high-level overview of the content and then display the content of the `metabric` dataset.
3.  What is the number of rows and columns in the dataset?
4.  Sort the dataset based on the `age_at_diagnosis` column.
5.  Sort the dataset based on the `Survival_time` column.

::: {.callout-note collapse="true"}
### Solution

```{python}
#| eval: false
# Print the top 5 rows of the `metabric` dataset
metabric.head()

# Print the bottom 5 rows of the `metabric` dataset
metabric.tail()

# high-level overview of the content
metabric.info()
metabric.describe()

# Print the no. of rows (records) and columns (features) in the `metabric` dataset
metabric.shape
# print number of rows only
df.shape[0]
# print number of columns only
df.shape[1]

# Sort based on the `age_at_diagnosis` column
df.sort_values("age_at_diagnosis)

# Sort based on the `Survival_time` column
df.sort_values("Survival_time)
```
:::

:::

## Selecting data

### Selecting based on labels

`DataFrame.loc()` is used to retrieve a group of rows and/or columns by labels in the DataFrame.

-   Selecting a row:

    ```{python}
    df.loc["R5"]
    ```

-   Selecting a range of rows:

    ```{python}
    df.loc[["R1", "R2", "R5"]]
    ```
    
    ```{python}
    df.loc["R2":"R4"]
    ```

-   Selecting a column:

    ```{python}
    df.loc[:, "E"]
    ```

-   Selecting a range of columns:

    ```{python}
    df.loc[:, ["A","C"]]
    ```
    
    ```{python}
    df.loc[:, "D":"F"]
    ```

-   Selecting a row and a column:

    ```{python}
    df.loc["R5", "A"]
    ```

-   Selecting a range of rows and columns:

    ```{python}
    df.loc["R3":"R5", "D":"F"]
    ```
    
    ```{python}
    df.loc[["R3","R2"], ["B","D","F"]]
    ```

-   Selecting a scalar using `DataFrame.at()` function:

    ```{python}
    df.at["R1", "A"]
    ```

### Selecting based on integer positions

`DataFrame.iloc()` is used to retrieve a group of rows and/or columns by integer position in the DataFrame. Note: integer position range from 0 to length-1 of rows or columns.

-   Selecting a row:

    ```{python}
    df.iloc[4]
    ```

-   Selecting a range of rows:

    ```{python}
    df.iloc[[0, 1, 4]]
    ```
    
    ```{python}
    df.iloc[2:6]
    ```

    -   Select top 3 rows
      
        ```{python}
        df.iloc[:3]
        ```
    
    -   Select all rows in the ascending order
    
        ```{python}
        df.iloc[::-1]
        ```

-   Selecting a column:

    ```{python}
    df.iloc[:, 4]
    ```

-   Selecting a range of columns:
    
    ```{python}
    df.iloc[:, [0, 2]]
    ```
    
    ```{python}
    df.iloc[:, 2:5]
    ```

-   Selecting a row and a column:

    ```{python}
    df.iloc[4, 0]
    ```

-   Selecting a range of rows and columns:

    ```{python}
    df.iloc[2:5, 3:6]
    ```
    
    ```{python}
    df.iloc[[1,3,5], [2,4]]
    ```

-   Selecting a scalar using `DataFrame.iat()` function:

    ```{python}
    df.iat[0, 1]
    ```

### Subset Variables - columns

![](images/subset-columns.png){width="500" fig-align="center"}

You can pass a list of columns to `[]` to select columns in that order.

-   Select a single column by name

    ```{python}
    df["E"]
    ```
    
    ```{python}
    df.E
    ```

-   Select a range of columns with specific names

    ```{python}
    df[["A","C"]]
    ```

-   To subset a DataFrame while excluding specific columns

    ```{python}
    df.drop(columns=["A","B"])
    ```
    
    ```{python}
    df.drop(["C","E", "F"], axis=1)
    ```

### Subset Observations - rows

![](images/subset-rows.png){width="500" fig-align="center"}

With DataFrame, slicing inside of `[]` **slices the rows**. This is provided largely as a convenience since it is such a common operation.

-   Select the first row

    ```{python}
    df[:1]
    ```

-   Select the first five row

    ```{python}
    df[:5]
    ```

-   Select a range of rows

    ```{python}
    df[3:6]
    ```

-   Select the last row

    ```{python}
    df[-1:]
    ```

-   Select the last three row

    ```{python}
    df[-3:]
    ```

-   Select a range of rows

    ```{python}
    df[-5:-2]
    ```

-   Select all rows in the ascending order

    ```{python}
    df[::-1]
    ```

### Subset by condition

Extract rows that meet a logical criteria.

-   Select rows where values in column C is greater than 6

    ```{python}
    above_6 = df["C"] > 6 # expression over the dataframe that returns a boolean vector 
    print(above_6)
    df[above_6]
    ```

-   Select rows where values in column D is less than or equal to 50

    ```{python}
    df[df["D"]<= 50]
    ```
    
    ```{python}
    df[df.D <= 50]
    ```

-   Using `isin()` function for filtering:

    ```{python}
    # select the rows with values orange and yellow
    df[df["E"].isin(["yellow", "orange"])]
    ```

-   Select rows with Column E is equal to `pink` or `blue`

    ```{python}
    df[df.E.isin(["pink", "blue"])]
    ```

-   Remove duplicate rows (only considers columns).

    ```{python}
    # Add a duplicate row (e.g., duplicating row "R5") to df
    df = pd.concat([df, df.loc[["R5"]]])
    df
    ```
    
    ```{python}
    df = df.drop_duplicates()
    df
    ```

-   Randomly select n rows.

    ```{python}
    df.sample(n=10) 
    ```

-   Randomly select fraction of rows.
    
    ```{python}
    df.sample(frac=0.5)
    ```

-   Select and order top n entries.

    ```{python}
    df.nlargest(3, 'D')
    ```

-   Select and order bottom n entries.

    ```{python}
    df.nsmallest(5, 'A')
    ```

-   To subset a DataFrame while excluding specific rows

    ```{python}
    df.drop(index=["R1","R2","R3"])
    ```
    
    ```{python}
    df.drop(["R2","R4","R6","R8"], axis=0)
    ```

### `filter` Function

The `filter()` function is used to **subset rows or columns** based on labels, such as column names or index labels. It is not used for filtering based on the actual values within the DataFrame but rather for subsetting by selecting specific rows or columns.

``` python
DataFrame.filter(items=None, like=None, regex=None, axis=None)
```

-   **items**: List of labels to filter based on.
-   **like**: Substring used to filter column or row names containing the provided string.
-   **regex**: Regular expression to filter column or row names.
-   **axis**: Specifies whether to filter on columns (`axis=1`) or rows (`axis=0`).

Load the `cms_hospital_patient_satisfaction.csv` file from the data folder into a DataFrame named `cms`, which will be used for the following examples.

```{python}
cms = pd.read_csv('data/patient_satisfaction/cms_hospital_patient_satisfaction.csv')
```

1.  **Filter by Specific Column Names**: Select columns "Facility Name" and "Overall Rating".

    ```{python}
    cms.filter(items=['Facility Name', 'Overall Rating'], axis=1)
    ```

2.  **Filter by Row Index Labels**: Select rows with index labels 1,3, 5.

    ```{python}
    cms.filter(items=[1,3,5], axis=0)
    ```

3.  **Filter Columns by Substring**: Select columns whose names contain the substring `"Rating"`.

    ```{python}
    cms.filter(like="Rating", axis=1)
    ```

4.  **Filter Columns by Regular Expression**: Select columns whose names start with the letter `"N"`.

    ```{python}
    cms.filter(regex="^N", axis=1)
    ```

5.  **Filter Rows by Regular Expression**: Select rows whose index has two digits.

    ```{python}
    cms.filter(regex="\d{2}", axis=0)
    ```

### `query()` Function

The `query()` function allows you to **filter rows** based on specific conditions applied to the values within the DataFrame. It enables writing SQL-like queries on a DataFrame using column names as variables.

``` python
DataFrame.query(expr, inplace=False, **kwargs)
```

-   **expr**: A string expression used for filtering.
-   **inplace**: Whether to perform the operation in place.
-   **kwargs**: Additional arguments (e.g., to pass column names with spaces).

1.  **Filter Rows Based on a Condition**: Select rows where the value in column `"Overall Rating"` is greater than 2.
    
    ```{python}
    cms.query("`Overall Rating` > 2")
    ```

2.  **Filter Rows Based on Multiple Conditions**: Select rows where `"Overall Rating"` is greater than 2 and the `"Response Rate"` is less than 30.

    ```{python}
    cms.query("`Overall Rating` > 2 and `Response Rate` < 30")
    ```

3.  **Filter Using a String Condition**: Select rows where `"County"` is equal to `"LOS ANGELES"`.

    ```{python}
    cms.query("County == 'LOS ANGELES'")
    ```

4.  **Filter Rows Using `or` Condition**: Select rows where `"Star Rating"` or `"`Overall Rating"\` is greater than 3.

    ```{python}
    cms.query("`Star Rating` > 3 or `Overall Rating` > 3")
    ```

5.  **Use Variable Inside `query()`**: Use a variable to filter rows dynamically.

    ```{python}
    threshold = 25
    cms.query("`Response Rate` > @threshold")
    ```

6.  **Filter Rows Based on Index**: Filter based on the index:

    ```{python}
    cms.query('index == 5')
    ```

## Setting data

Once a subset of data is filtered using any of the methods discussed before the assignment operator can be used to assign different data. A few examples is shown below.

Consider the following DataFrame for the examples listed below,

```{python}
df
```

-   Update a single cell in the DataFrame:

    ```{python}
    df.at["R1", "A"] = 1.0
    df.head()
    ```

-   Update multiple cells in the DataFrame:

    ```{python}
    # select the rows with values orange and yellow
    df_sub = df[df.E.isin(["yellow", "orange"])]
    
    df_sub["E"] = ["red", "green"]
    df_sub
    ```

    The above command shows a warning which says that we are trying to set (or update) values of a copy of a DataFrame rather than the original DataFrame. Recall that `df_sub["E"] = df[df["E"].isin(["yellow", "orange"])]`, that means we are trying to update yellow and orange in the DataFrame to red and green. However, since we are updating a copy of the DataFrame, row R9 and R12 of the DataFrame `df` is not still updated as shown below.
    
    ```{python}
    df
    ```
    
    If we want to update the original DataFrame, we should set as follows.
    
    ```{python}
    df.loc[df.E.isin(["yellow", "orange"]), "E"] = ["red", "green"]
    df
    ```

-   Another useful function within this library is the `replace()` function which find a value(s) on a DataFrame and replace it with another value on all columns and rows.\

    ```{python}
    df.replace('red', 'blue')
    ```

-   Adding a new row to the DataFrame:
    
    ```{python}
    # Add a new row using `loc[]`
    df.loc['R15'] = [0.891133, pd.to_datetime("2023-01-16"), 13, 30, 'blue', 'foo']
    df
    ```
    
    ```{python}
    # Add a new row using `append()`
    new_row = pd.DataFrame({'A': [0.425755], 'B': pd.to_datetime("2023-01-17")}, index=['R17'])
    df = pd.concat([df, new_row])
    df
    ```

-   Setting values in a categorical column works as long as the value is included in the categories:
    
    ```{python}
    #| error: true
    # assign a column as a categorical column
    cms['Hospital Type'] = pd.Categorical(cms['Hospital Type']) 
    
    # update a value
    cms.loc[1, 'Hospital Type'] = 'Specialty Hospital'
    ```
    
    This result in an error stating that Python cannot set item on a Categorical column with a new category (Specialty Hospital), that is not defined. To fix this error you can define the categories explicitly as follows:
    
    ```{python}
    # Define a categorical column with fixed categories
    cms['Hospital Type'] = pd.Categorical(cms['Hospital Type'], categories=['Acute Care Hospital', 'Critical Access Hospital', 'Specialty Hospital']) 
    
    # update a value
    cms.loc[1, 'Hospital Type'] = 'Specialty Hospital'
    
    cms
    ```

This concludes the introduction to the Pandas section. In the next section, we will dive into data manipulation using Pandas. We will explore various functions within this library to generate basic statistics, providing a clearer understanding of the underlying data.

---